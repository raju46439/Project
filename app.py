# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16obR47-ZuaYcgfaG4DD9YSjQTAaAcF93
"""

# app.py
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# --- Page setup ---
st.set_page_config(page_title="Global Development Clustering", layout="wide")
st.title("üåç Global Development Clustering App")

# --- File Upload ---
uploaded_file = st.file_uploader("Upload your dataset (CSV or Excel)", type=["csv", "xlsx"])

if uploaded_file is not None:
    # --- Load Data ---
    if uploaded_file.name.endswith(".csv"):
        df = pd.read_csv(uploaded_file)
    else:
        df = pd.read_excel(uploaded_file)

    # drop extra column if present
    df = df.drop(columns=["Number of Records"], errors="ignore")

    # clean symbols like $, %
    for col in df.columns:
        df[col] = df[col].astype(str).str.replace(r"[\$,%]", "", regex=True)
        try:
            df[col] = df[col].astype(float)
        except:
            pass

    # encode country column
    if "Country" in df.columns:
        le = LabelEncoder()
        df["Country_encoded"] = le.fit_transform(df["Country"])
        df.drop("Country", axis=1, inplace=True)

    # factorize categorical columns
    for col in df.select_dtypes(exclude="number").columns:
        df[col] = pd.factorize(df[col])[0].astype(float)

    # fill missing numbers with median
    df = df.fillna(df.median(numeric_only=True))

    # --- Preprocessing ---
    numeric_df = df.select_dtypes(include=["float64", "int64"])
    scaler = StandardScaler()
    df_scaled = scaler.fit_transform(numeric_df)

    # --- Sidebar options ---
    st.sidebar.header("Clustering Options")
    model_choice = st.sidebar.selectbox("Choose Model", ["KMeans", "DBSCAN", "Hierarchical"])
    n_clusters = st.sidebar.slider("Number of Clusters", 2, 10, 4)
    eps = st.sidebar.slider("DBSCAN eps", 0.5, 5.0, 1.5)
    min_samples = st.sidebar.slider("DBSCAN min_samples", 2, 10, 5)

    # --- Clustering ---
    if model_choice == "KMeans":
        model = KMeans(n_clusters=n_clusters, random_state=42)
        labels = model.fit_predict(df_scaled)
    elif model_choice == "DBSCAN":
        model = DBSCAN(eps=eps, min_samples=min_samples)
        labels = model.fit_predict(df_scaled)
    else:
        model = AgglomerativeClustering(n_clusters=n_clusters)
        labels = model.fit_predict(df_scaled)

    df["Cluster"] = labels

    # --- Show Results ---
    st.subheader("Clustered Data")
    st.dataframe(df.head())

    # --- Cluster Summary ---
    st.subheader("Cluster Summary (mean values)")
    summary = df.groupby("Cluster")[numeric_df.columns].mean().round(2)
    st.dataframe(summary)

    # --- PCA Visualization ---
    st.subheader("PCA Visualization of Clusters")
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(df_scaled)

    fig, ax = plt.subplots(figsize=(8, 6))
    scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=df["Cluster"], cmap="tab10", s=60)
    ax.set_xlabel("PC1")
    ax.set_ylabel("PC2")
    ax.set_title("Clusters in PCA Space")
    st.pyplot(fig)

else:
    st.info("üëÜ Please upload a CSV or Excel file to begin.")